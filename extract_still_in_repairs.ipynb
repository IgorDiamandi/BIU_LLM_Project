{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66b6c1b-08ce-4ead-96fd-c2eebd5c598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import boto3\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from anthropic import Anthropic\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_config():\n",
    "    with open('config/config.yaml', 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_aws_client(config):\n",
    "    return boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=config['aws']['aws_access_key_id'],\n",
    "        aws_secret_access_key=config['aws']['aws_secret_access_key'],\n",
    "        region_name=config['aws']['region_name']\n",
    "    )\n",
    "\n",
    "def init_claude(config):\n",
    "    return Anthropic(\n",
    "        api_key=config['anthropic']['claud_key']\n",
    "    )\n",
    "\n",
    "def get_s3_public_url(bucket_name, file_key, region):\n",
    "    return f\"https://{bucket_name}.s3.{region}.amazonaws.com/{file_key}\"\n",
    "\n",
    "def ensure_tmp_dir():\n",
    "    \"\"\"Create tmp directory in the working folder if it doesn't exist\"\"\"\n",
    "    tmp_dir = os.path.join(os.getcwd(), 'tmp')\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "    else:\n",
    "        # Clean existing files in tmp directory\n",
    "        for filename in os.listdir(tmp_dir):\n",
    "            file_path = os.path.join(tmp_dir, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Error deleting {file_path}: {e}')\n",
    "    return tmp_dir"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13279fba-1b5f-4441-af60-fd44ab0dd445",
   "metadata": {},
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract both regular text and text from images in PDF\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_content = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Extract regular text\n",
    "        text_content.append(page.get_text())\n",
    "        \n",
    "        # Extract images and their text content\n",
    "        image_list = page.get_images()\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            try:\n",
    "                # Get image data\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                \n",
    "                # Convert to PIL Image for potential future processing\n",
    "                image = Image.open(io.BytesIO(image_bytes))\n",
    "                text_content.append(f\"[Embedded Image {page_num + 1}-{img_index + 1}]\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting image {img_index} from page {page_num}: {str(e)}\")\n",
    "    \n",
    "    doc.close()\n",
    "    return \"\\n\".join(text_content)\n",
    "\n",
    "def analyze_with_claude(client, text):\n",
    "    prompt = \"\"\" Analyze this document and extract the following information in JSON format. The text contains course syllabus information, likely in both Hebrew and English. The document may contain references to embedded images. Required JSON structure: { \"course_name\": \"Course name in original language\", \"program_manager\": \"Look for 'מנהל התוכנית' or program manager\", \"instructors\": [ { \"name\": \"Instructor name\", \"role\": \"Role (e.g., יועץ מקצועי, מרצה, מרצה בכיר, מדריך)\", \"title\": \"Professional title if available\", \"description\": \"Additional description or background\" } ], \"summary\": \"A comprehensive summary of the course content\", \"embedded_images\": [\"Simple list of image names/references found in text\"], \"full_text\": \"The complete text from the document\" } Keep all text in its original language (Hebrew or English). Ensure proper extraction of Hebrew text and names. If a field is not found, use null or empty array []. Place the complete input text in the full_text field. Note any embedded image references found in the text in the embedded_images array. Document text: {text} \"\"\"\n",
    "    \n",
    "    try:\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-3-sonnet-20240229\",\n",
    "            max_tokens=100000,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt.format(text=text)\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Get the response text and clean it up\n",
    "        response_text = message.content[0].text.strip()\n",
    "        \n",
    "        # Try to find the JSON part in the response\n",
    "        try:\n",
    "            # Find the first { and last } to extract just the JSON part\n",
    "            start = response_text.find('{')\n",
    "            end = response_text.rfind('}') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                json_str = response_text[start:end]\n",
    "                claude_response = json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Parse Error: {str(e)}\")\n",
    "            print(f\"Response text: {response_text}\")\n",
    "            raise\n",
    "        \n",
    "        # Create ordered dictionary for the final response\n",
    "        ordered_response = OrderedDict([\n",
    "            (\"course_name\", claude_response.get(\"course_name\", \"\")),\n",
    "            (\"program_manager\", claude_response.get(\"program_manager\", \"\")),\n",
    "            (\"instructors\", claude_response.get(\"instructors\", [])),\n",
    "            (\"summary\", claude_response.get(\"summary\", \"\")),\n",
    "            (\"embedded_images\", claude_response.get(\"embedded_images\", [])),\n",
    "            (\"full_text\", claude_response.get(\"full_text\", text))\n",
    "        ])\n",
    "        \n",
    "        return ordered_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing with Claude: {str(e)}\")\n",
    "        print(f\"Full error context: \", e)\n",
    "        return OrderedDict([\n",
    "            (\"course_name\", \"\"),\n",
    "            (\"program_manager\", \"\"),\n",
    "            (\"instructors\", []),\n",
    "            (\"summary\", \"Error analyzing content\"),\n",
    "            (\"embedded_images\", []),\n",
    "            (\"full_text\", text)\n",
    "        ])\n",
    "\n",
    "\n",
    "def process_files(config):\n",
    "    s3_client = init_aws_client(config)\n",
    "    claude_client = init_claude(config)\n",
    "    \n",
    "    # Create and ensure tmp directory is clean\n",
    "    tmp_dir = ensure_tmp_dir()\n",
    "    \n",
    "    # Create local directory for JSON files\n",
    "    json_output_dir = os.path.join(os.getcwd(), 'output', 'json')\n",
    "    os.makedirs(json_output_dir, exist_ok=True)\n",
    "    \n",
    "    # List all files in the upload bucket/path\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(\n",
    "        Bucket=config['aws']['upload_bucket_name'],\n",
    "        Prefix=config['aws']['upload_path']\n",
    "    )\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page.get('Contents', []):\n",
    "            file_key = obj['Key']\n",
    "            file_name = os.path.basename(file_key)\n",
    "            \n",
    "            # Only process PDFs\n",
    "            if not file_name.lower().endswith('.pdf'):\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing file: {file_name}\")\n",
    "            \n",
    "            # Create paths for temporary PDF and output JSON\n",
    "            tmp_pdf_path = os.path.join(tmp_dir, file_name)\n",
    "            json_filename = f\"{os.path.splitext(file_name)[0]}.json\"\n",
    "            local_json_path = os.path.join(json_output_dir, json_filename)\n",
    "            \n",
    "            try:\n",
    "                # Download file to temporary location\n",
    "                s3_client.download_file(\n",
    "                    config['aws']['upload_bucket_name'],\n",
    "                    file_key,\n",
    "                    tmp_pdf_path\n",
    "                )\n",
    "\n",
    "                # Extract text (including image references)\n",
    "                extracted_text = extract_text_from_pdf(tmp_pdf_path)\n",
    "                \n",
    "                # Analyze with Claude\n",
    "                analysis = analyze_with_claude(claude_client, extracted_text)\n",
    "                \n",
    "                # Create final JSON with file_url as first item\n",
    "                final_output = OrderedDict([\n",
    "                    (\"file_url\", get_s3_public_url(\n",
    "                        config['aws']['upload_bucket_name'],\n",
    "                        file_key,\n",
    "                        config['aws']['region_name']\n",
    "                    ))\n",
    "                ])\n",
    "                final_output.update(analysis)\n",
    "                \n",
    "                # Save JSON locally\n",
    "                with open(local_json_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(final_output, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                # Save to S3 (ensure forward slashes for S3 path)\n",
    "                json_key = os.path.join(\n",
    "                    config['aws']['extract_txt_path'],\n",
    "                    json_filename\n",
    "                ).replace('\\\\', '/')  # Convert Windows path separators to forward slashes\n",
    "                \n",
    "                s3_client.put_object(\n",
    "                    Bucket=config['aws']['txt_extract_bucket_name'],\n",
    "                    Key=json_key,\n",
    "                    Body=json.dumps(final_output, ensure_ascii=False, indent=2).encode('utf-8')\n",
    "                )\n",
    "\n",
    "                print(f\"Successfully processed and saved: {file_name}\")\n",
    "                print(f\"JSON saved locally at: {local_json_path}\")\n",
    "                print(f\"JSON uploaded to S3: s3://{config['aws']['txt_extract_bucket_name']}/{json_key}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {str(e)}\")\n",
    "                print(f\"Full error context: \", e)\n",
    "            \n",
    "            finally:\n",
    "                # Clean up the temporary PDF file\n",
    "                if os.path.exists(tmp_pdf_path):\n",
    "                    try:\n",
    "                        os.remove(tmp_pdf_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing temporary file {tmp_pdf_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    config = load_config()\n",
    "    process_files(config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38d459aa-4744-429c-8a24-4eb07b8e3480",
   "metadata": {},
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from entire PDF as one continuous document\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Get all text from the document as one piece\n",
    "    text_content = doc.get_page_text(\"all\")  # Gets continuous text from entire document\n",
    "    \n",
    "    # Get all images from the document\n",
    "    image_references = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        for img_index, img in enumerate(page.get_images()):\n",
    "            try:\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image = Image.open(io.BytesIO(image_bytes))\n",
    "                image_references.append(f\"[Embedded Image {page_num + 1}-{img_index + 1}]\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting image {img_index} from page {page_num}: {str(e)}\")\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    # Combine text and image references\n",
    "    if image_references:\n",
    "        text_content += \"\\n\\nEmbedded Images:\\n\" + \"\\n\".join(image_references)\n",
    "    \n",
    "    return text_content\n",
    "\n",
    "def analyze_with_claude(client, text):\n",
    "    prompt = \"\"\"You are a PDF analysis expert. Analyze this document and extract the following information in a clean JSON format:\n",
    "\n",
    "{\n",
    "    \"course_name\": \"Extract the course name in its original language (Hebrew or English)\",\n",
    "    \"program_manager\": \"Find the program manager (look for 'מנהל התוכנית' or 'program manager')\",\n",
    "    \"instructors\": [\n",
    "        {\n",
    "            \"name\": \"Instructor's name\",\n",
    "            \"role\": \"Their role (e.g., יועץ מקצועי, מרצה, מרצה בכיר, מדריך)\",\n",
    "            \"title\": \"Professional title if available\",\n",
    "            \"description\": \"Any additional background information\"\n",
    "        }\n",
    "    ],\n",
    "    \"summary\": \"A comprehensive summary of the course content\",\n",
    "    \"embedded_images\": [\"List of embedded image references\"],\n",
    "    \"full_text\": \"The complete document text\"\n",
    "}\n",
    "\n",
    "Keep all text in its original language. If a field is not found, use null or empty array [].\n",
    "\n",
    "Document text: {text}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-3.5-sonnet\",\n",
    "            max_tokens=100000,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt.format(text=text)\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Debug: Print raw response\n",
    "        print(\"Raw Claude Response:\", message.content[0].text)\n",
    "        \n",
    "        response_text = message.content[0].text.strip()\n",
    "        \n",
    "        try:\n",
    "            # Extract JSON object\n",
    "            start = response_text.find('{')\n",
    "            end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if start != -1 and end != 0:\n",
    "                json_str = response_text[start:end]\n",
    "                print(\"Extracted JSON string:\", json_str)  # Debug\n",
    "                claude_response = json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON found in Claude response\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Parse Error: {str(e)}\")\n",
    "            print(f\"Attempted to parse: {response_text}\")\n",
    "            raise\n",
    "        \n",
    "        return OrderedDict([\n",
    "            (\"course_name\", claude_response.get(\"course_name\", \"\")),\n",
    "            (\"program_manager\", claude_response.get(\"program_manager\", \"\")),\n",
    "            (\"instructors\", claude_response.get(\"instructors\", [])),\n",
    "            (\"summary\", claude_response.get(\"summary\", \"\")),\n",
    "            (\"embedded_images\", claude_response.get(\"embedded_images\", [])),\n",
    "            (\"full_text\", claude_response.get(\"full_text\", text))\n",
    "        ])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing with Claude: {str(e)}\")\n",
    "        print(f\"Full error context: \", e)\n",
    "        return OrderedDict([\n",
    "            (\"course_name\", \"\"),\n",
    "            (\"program_manager\", \"\"),\n",
    "            (\"instructors\", []),\n",
    "            (\"summary\", f\"Error analyzing content: {str(e)}\"),\n",
    "            (\"embedded_images\", []),\n",
    "            (\"full_text\", text)\n",
    "        ])\n",
    "\n",
    "def process_files(config):\n",
    "    s3_client = init_aws_client(config)\n",
    "    claude_client = init_claude(config)\n",
    "    \n",
    "    tmp_dir = ensure_tmp_dir()\n",
    "    json_output_dir = os.path.join(os.getcwd(), 'output', 'json')\n",
    "    os.makedirs(json_output_dir, exist_ok=True)\n",
    "    \n",
    "    def list_all_pdfs(bucket, prefix):\n",
    "        \"\"\"Recursively list all PDFs in bucket/prefix\"\"\"\n",
    "        pdf_files = []\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    if obj['Key'].lower().endswith('.pdf'):\n",
    "                        pdf_files.append(obj)\n",
    "        \n",
    "        return pdf_files\n",
    "\n",
    "    # Get all PDF files recursively\n",
    "    pdf_files = list_all_pdfs(\n",
    "        config['aws']['upload_bucket_name'],\n",
    "        config['aws']['upload_path']\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_obj in pdf_files:\n",
    "        file_key = pdf_obj['Key']\n",
    "        file_name = os.path.basename(file_key)\n",
    "        \n",
    "        print(f\"\\nProcessing: {file_key}\")\n",
    "        \n",
    "        tmp_pdf_path = os.path.join(tmp_dir, file_name)\n",
    "        json_filename = f\"{os.path.splitext(file_name)[0]}.json\"\n",
    "        local_json_path = os.path.join(json_output_dir, json_filename)\n",
    "        \n",
    "        try:\n",
    "            # Download PDF\n",
    "            print(f\"Downloading {file_key}\")\n",
    "            s3_client.download_file(\n",
    "                config['aws']['upload_bucket_name'],\n",
    "                file_key,\n",
    "                tmp_pdf_path\n",
    "            )\n",
    "\n",
    "            # Extract and analyze\n",
    "            print(\"Extracting text...\")\n",
    "            extracted_text = extract_text_from_pdf(tmp_pdf_path)\n",
    "            \n",
    "            print(\"Analyzing with Claude...\")\n",
    "            analysis = analyze_with_claude(claude_client, extracted_text)\n",
    "            \n",
    "            # Prepare output\n",
    "            final_output = OrderedDict([\n",
    "                (\"file_url\", get_s3_public_url(\n",
    "                    config['aws']['upload_bucket_name'],\n",
    "                    file_key,\n",
    "                    config['aws']['region_name']\n",
    "                )),\n",
    "                (\"file_path\", file_key),\n",
    "                (\"file_name\", file_name)\n",
    "            ])\n",
    "            final_output.update(analysis)\n",
    "            \n",
    "            # Save locally\n",
    "            with open(local_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_output, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Upload to S3\n",
    "            json_key = os.path.join(\n",
    "                config['aws']['extract_txt_path'],\n",
    "                json_filename\n",
    "            ).replace('\\\\', '/')\n",
    "            \n",
    "            s3_client.put_object(\n",
    "                Bucket=config['aws']['txt_extract_bucket_name'],\n",
    "                Key=json_key,\n",
    "                Body=json.dumps(final_output, ensure_ascii=False, indent=2).encode('utf-8')\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully processed: {file_name}\")\n",
    "            print(f\"JSON saved: {local_json_path}\")\n",
    "            print(f\"Uploaded to: s3://{config['aws']['txt_extract_bucket_name']}/{json_key}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}:\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            if os.path.exists(tmp_pdf_path):\n",
    "                try:\n",
    "                    os.remove(tmp_pdf_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error cleaning up {tmp_pdf_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        config = load_config()\n",
    "        process_files(config)\n",
    "    except Exception as e:\n",
    "        print(f\"Main process error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8294ff3e-ea17-459e-abdd-5cd5ceeb6507",
   "metadata": {},
   "source": [
    "def analyze_with_claude(client, file_path, file_type):\n",
    "    \"\"\"Send file directly to Claude for analysis\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_content = file.read()\n",
    "        \n",
    "    # Same prompt for all file types\n",
    "    prompt = \"\"\"Analyze this document and extract the following information in JSON format. The document contains course syllabus information, likely in both Hebrew and English. Required JSON structure: { \"course_name\": \"Course name in original language\", \"program_manager\": \"Look for 'מנהל התוכנית' or program manager\", \"instructors\": [ { \"name\": \"Instructor name\", \"role\": \"Role (e.g., יועץ מקצועי, מרצה, מרצה בכיר, מדריך)\", \"title\": \"Professional title if available\", \"description\": \"Additional description or background\" } ], \"summary\": \"A comprehensive summary of the course content\", \"embedded_images\": [\"List of image references\"], \"full_text\": \"The complete text from the document\" } Keep all text in its original language (Hebrew and English). If a field is not found, use null or empty array [].\"\"\"\n",
    "\n",
    "    # Set media type based on file extension\n",
    "    media_types = {\n",
    "        \"pdf\": \"application/pdf\",\n",
    "        \"jpg\": \"image/jpeg\",\n",
    "        \"jpeg\": \"image/jpeg\",\n",
    "        \"png\": \"image/png\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-3.5-sonnet\",\n",
    "            max_tokens=100000,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"file\",\n",
    "                            \"file_path\": file_path,\n",
    "                            \"media_type\": media_types[file_type]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Debug: Print raw response\n",
    "        print(\"Raw Claude Response:\", message.content[0].text[:500] + \"...\")\n",
    "        \n",
    "        response_text = message.content[0].text.strip()\n",
    "        \n",
    "        try:\n",
    "            start = response_text.find('{')\n",
    "            end = response_text.rfind('}') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                json_str = response_text[start:end]\n",
    "                print(\"Extracted JSON string:\", json_str[:500] + \"...\")\n",
    "                claude_response = json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Parse Error: {str(e)}\")\n",
    "            print(f\"Response text: {response_text}\")\n",
    "            raise\n",
    "        \n",
    "        return OrderedDict([\n",
    "            (\"course_name\", claude_response.get(\"course_name\", \"\")),\n",
    "            (\"program_manager\", claude_response.get(\"program_manager\", \"\")),\n",
    "            (\"instructors\", claude_response.get(\"instructors\", [])),\n",
    "            (\"summary\", claude_response.get(\"summary\", \"\")),\n",
    "            (\"embedded_images\", claude_response.get(\"embedded_images\", [])),\n",
    "            (\"full_text\", claude_response.get(\"full_text\", \"\"))\n",
    "        ])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing with Claude: {str(e)}\")\n",
    "        print(f\"Full error context: \", e)\n",
    "        return OrderedDict([\n",
    "            (\"course_name\", \"\"),\n",
    "            (\"program_manager\", \"\"),\n",
    "            (\"instructors\", []),\n",
    "            (\"summary\", f\"Error analyzing content: {str(e)}\"),\n",
    "            (\"embedded_images\", []),\n",
    "            (\"full_text\", \"\")\n",
    "        ])\n",
    "\n",
    "def process_files(config):\n",
    "    s3_client = init_aws_client(config)\n",
    "    claude_client = init_claude(config)\n",
    "    \n",
    "    tmp_dir = ensure_tmp_dir()\n",
    "    json_output_dir = os.path.join(os.getcwd(), 'output', 'json')\n",
    "    os.makedirs(json_output_dir, exist_ok=True)\n",
    "    \n",
    "    def list_all_files(bucket, prefix):\n",
    "        \"\"\"Recursively list all supported files in bucket/prefix\"\"\"\n",
    "        files = []\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    file_ext = os.path.splitext(obj['Key'])[1].lower()\n",
    "                    if file_ext in ['.pdf', '.jpg', '.jpeg', '.png']:\n",
    "                        files.append(obj)\n",
    "        \n",
    "        return files\n",
    "\n",
    "    # Get all files recursively\n",
    "    files = list_all_files(\n",
    "        config['aws']['upload_bucket_name'],\n",
    "        config['aws']['upload_path']\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(files)} files to process\")\n",
    "    \n",
    "    for file_obj in files:\n",
    "        file_key = file_obj['Key']\n",
    "        file_name = os.path.basename(file_key)\n",
    "        file_ext = os.path.splitext(file_name)[1].lower()[1:]  # Remove the dot\n",
    "        \n",
    "        print(f\"\\nProcessing: {file_key}\")\n",
    "        \n",
    "        tmp_file_path = os.path.join(tmp_dir, file_name)\n",
    "        json_filename = f\"{os.path.splitext(file_name)[0]}.json\"\n",
    "        local_json_path = os.path.join(json_output_dir, json_filename)\n",
    "        \n",
    "        try:\n",
    "            # Download file\n",
    "            print(f\"Downloading {file_key}\")\n",
    "            s3_client.download_file(\n",
    "                config['aws']['upload_bucket_name'],\n",
    "                file_key,\n",
    "                tmp_file_path\n",
    "            )\n",
    "\n",
    "            # Analyze with Claude\n",
    "            print(f\"Analyzing {file_ext.upper()} with Claude...\")\n",
    "            analysis = analyze_with_claude(claude_client, tmp_file_path, file_ext)\n",
    "            \n",
    "            # Prepare output\n",
    "            final_output = OrderedDict([\n",
    "                (\"file_url\", get_s3_public_url(\n",
    "                    config['aws']['upload_bucket_name'],\n",
    "                    file_key,\n",
    "                    config['aws']['region_name']\n",
    "                )),\n",
    "                (\"file_path\", file_key),\n",
    "                (\"file_name\", file_name),\n",
    "                (\"file_type\", file_ext)\n",
    "            ])\n",
    "            final_output.update(analysis)\n",
    "            \n",
    "            # Save locally\n",
    "            with open(local_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_output, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Upload to S3\n",
    "            json_key = os.path.join(\n",
    "                config['aws']['extract_txt_path'],\n",
    "                json_filename\n",
    "            ).replace('\\\\', '/')\n",
    "            \n",
    "            s3_client.put_object(\n",
    "                Bucket=config['aws']['txt_extract_bucket_name'],\n",
    "                Key=json_key,\n",
    "                Body=json.dumps(final_output, ensure_ascii=False, indent=2).encode('utf-8')\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully processed: {file_name}\")\n",
    "            print(f\"JSON saved: {local_json_path}\")\n",
    "            print(f\"Uploaded to: s3://{config['aws']['txt_extract_bucket_name']}/{json_key}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}:\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            if os.path.exists(tmp_file_path):\n",
    "                try:\n",
    "                    os.remove(tmp_file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error cleaning up {tmp_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eca0b06-d0af-446f-aa7f-86ea733c0bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 PDF files to process\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/AWS Practitioner Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/AWS Practitioner Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing AWS Practitioner Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/AWS Solution Architect Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/AWS Solution Architect Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing AWS Solution Architect Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Advanced Project Management Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Advanced Project Management Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing Advanced Project Management Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/BI Fin Ops Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/BI Fin Ops Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing BI Fin Ops Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CC Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CC Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CC Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CCNA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CCNA Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CCNA Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CCSP Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CCSP Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CCSP Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CDAIO-CDO Intro.pdf\n",
      "Downloading ds/rag01/sources/PDF/CDAIO-CDO Intro.pdf\n",
      "Extracting text...\n",
      "Error processing CDAIO-CDO Intro.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CDAIO-CDO Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CDAIO-CDO Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CDAIO-CDO Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CISCO CCNA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CISCO CCNA Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CISCO CCNA Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CISO Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CISO Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CISO Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CISSP Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CISSP Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CISSP Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CND Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CND Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing CND Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Check Point CCSA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Check Point CCSA Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing Check Point CCSA Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DMP Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DMP Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing DMP Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DPO Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DPO Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing DPO Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DS & AI for Managers Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DS & AI for Managers Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing DS & AI for Managers Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Data Science Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Data Science Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing Data Science Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DevSecOps Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DevSecOps Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing DevSecOps Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/FinOps Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/FinOps Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing FinOps Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Fortinet NSE Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Fortinet NSE Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing Fortinet NSE Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Product Management Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Product Management Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing Product Management Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/QA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/QA Sylabus.pdf\n",
      "Extracting text...\n",
      "Error processing QA Sylabus.pdf:\n",
      "Error type: AssertionError\n",
      "Error message: Invalid item number: i='all'.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "317bb16f-f2c6-4cb7-98a2-4479af7ad304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import boto3\n",
    "import io\n",
    "from PIL import Image\n",
    "from anthropic import Anthropic\n",
    "from collections import OrderedDict\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load configuration from YAML file\"\"\"\n",
    "    with open('config/config.yaml', 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_aws_client(config):\n",
    "    \"\"\"Initialize AWS S3 client\"\"\"\n",
    "    return boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=config['aws']['aws_access_key_id'],\n",
    "        aws_secret_access_key=config['aws']['aws_secret_access_key'],\n",
    "        region_name=config['aws']['region_name']\n",
    "    )\n",
    "\n",
    "def init_claude(config):\n",
    "    \"\"\"Initialize Claude client\"\"\"\n",
    "    return Anthropic(\n",
    "        api_key=config['anthropic']['claud_key']\n",
    "    )\n",
    "\n",
    "def get_s3_public_url(bucket_name, file_key, region):\n",
    "    \"\"\"Generate S3 public URL\"\"\"\n",
    "    return f\"https://{bucket_name}.s3.{region}.amazonaws.com/{file_key}\"\n",
    "\n",
    "def ensure_tmp_dir():\n",
    "    \"\"\"Create and clean temporary directory\"\"\"\n",
    "    tmp_dir = os.path.join(os.getcwd(), 'tmp')\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "    else:\n",
    "        for filename in os.listdir(tmp_dir):\n",
    "            file_path = os.path.join(tmp_dir, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Error deleting {file_path}: {e}')\n",
    "    return tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00f6501c-10d5-4293-82d3-4e3244aa19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_claude(client, file_path, file_type):\n",
    "    \"\"\"Send file to Claude for analysis\"\"\"\n",
    "    prompt = \"\"\"Analyze this document and extract the following information in JSON format. The document contains course syllabus information, likely in both Hebrew and English. Required JSON structure: { \"course_name\": \"Course name in original language\", \"program_manager\": \"Look for 'מנהל התוכנית' or program manager\", \"instructors\": [ { \"name\": \"Instructor name\", \"role\": \"Role (e.g., יועץ מקצועי, מרצה, מרצה בכיר, מדריך)\", \"title\": \"Professional title if available\", \"description\": \"Additional description or background\" } ], \"summary\": \"A comprehensive summary of the course content\", \"embedded_images\": [\"List of image references\"], \"full_text\": \"The complete text from the document\" } Keep all text in its original language (Hebrew and English). If a field is not found, use null or empty array [].\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            file_content = file.read()\n",
    "\n",
    "        if file_type == 'pdf':\n",
    "            # For PDFs\n",
    "            message = client.messages.create(\n",
    "                model=\"claude-3.5-sonnet\",\n",
    "                max_tokens=100000,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image\",\n",
    "                                \"source\": {\n",
    "                                    \"type\": \"base64\",\n",
    "                                    \"media_type\": \"application/pdf\",\n",
    "                                    \"data\": base64.b64encode(file_content).decode('utf-8')\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            # For images (jpg, jpeg, png)\n",
    "            message = client.messages.create(\n",
    "                model=\"claude-3.5-sonnet\",\n",
    "                max_tokens=100000,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image\",\n",
    "                                \"source\": {\n",
    "                                    \"type\": \"base64\",\n",
    "                                    \"media_type\": f\"image/{file_type}\",\n",
    "                                    \"data\": base64.b64encode(file_content).decode('utf-8')\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        print(\"Raw Claude Response:\", message.content[0].text[:500] + \"...\")\n",
    "        response_text = message.content[0].text.strip()\n",
    "        \n",
    "        try:\n",
    "            start = response_text.find('{')\n",
    "            end = response_text.rfind('}') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                json_str = response_text[start:end]\n",
    "                print(\"Extracted JSON string:\", json_str[:500] + \"...\")\n",
    "                claude_response = json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Parse Error: {str(e)}\")\n",
    "            print(f\"Response text: {response_text}\")\n",
    "            raise\n",
    "        \n",
    "        return OrderedDict([\n",
    "            (\"course_name\", claude_response.get(\"course_name\", \"\")),\n",
    "            (\"program_manager\", claude_response.get(\"program_manager\", \"\")),\n",
    "            (\"instructors\", claude_response.get(\"instructors\", [])),\n",
    "            (\"summary\", claude_response.get(\"summary\", \"\")),\n",
    "            (\"embedded_images\", claude_response.get(\"embedded_images\", [])),\n",
    "            (\"full_text\", claude_response.get(\"full_text\", \"\"))\n",
    "        ])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing with Claude: {str(e)}\")\n",
    "        print(f\"Full error context: \", e)\n",
    "        return OrderedDict([\n",
    "            (\"course_name\", \"\"),\n",
    "            (\"program_manager\", \"\"),\n",
    "            (\"instructors\", []),\n",
    "            (\"summary\", f\"Error analyzing content: {str(e)}\"),\n",
    "            (\"embedded_images\", []),\n",
    "            (\"full_text\", \"\")\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3b9fc6f-dbe7-4117-be86-d8988b122d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(config):\n",
    "    \"\"\"Main processing function\"\"\"\n",
    "    s3_client = init_aws_client(config)\n",
    "    claude_client = init_claude(config)\n",
    "    \n",
    "    tmp_dir = ensure_tmp_dir()\n",
    "    json_output_dir = os.path.join(os.getcwd(), 'output', 'json')\n",
    "    os.makedirs(json_output_dir, exist_ok=True)\n",
    "    \n",
    "    def list_all_files(bucket, prefix):\n",
    "        \"\"\"Recursively list all supported files\"\"\"\n",
    "        files = []\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    file_ext = os.path.splitext(obj['Key'])[1].lower()\n",
    "                    if file_ext in ['.pdf', '.jpg', '.jpeg', '.png']:\n",
    "                        files.append(obj)\n",
    "        \n",
    "        return files\n",
    "\n",
    "    files = list_all_files(\n",
    "        config['aws']['upload_bucket_name'],\n",
    "        config['aws']['upload_path']\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(files)} files to process\")\n",
    "    \n",
    "    for file_obj in files:\n",
    "        file_key = file_obj['Key']\n",
    "        file_name = os.path.basename(file_key)\n",
    "        file_ext = os.path.splitext(file_name)[1].lower()[1:]\n",
    "        \n",
    "        print(f\"\\nProcessing: {file_key}\")\n",
    "        \n",
    "        tmp_file_path = os.path.join(tmp_dir, file_name)\n",
    "        json_filename = f\"{os.path.splitext(file_name)[0]}.json\"\n",
    "        local_json_path = os.path.join(json_output_dir, json_filename)\n",
    "        \n",
    "        try:\n",
    "            print(f\"Downloading {file_key}\")\n",
    "            s3_client.download_file(\n",
    "                config['aws']['upload_bucket_name'],\n",
    "                file_key,\n",
    "                tmp_file_path\n",
    "            )\n",
    "\n",
    "            print(f\"Analyzing {file_ext.upper()} with Claude...\")\n",
    "            analysis = analyze_with_claude(claude_client, tmp_file_path, file_ext)\n",
    "            \n",
    "            final_output = OrderedDict([\n",
    "                (\"file_url\", get_s3_public_url(\n",
    "                    config['aws']['upload_bucket_name'],\n",
    "                    file_key,\n",
    "                    config['aws']['region_name']\n",
    "                )),\n",
    "                (\"file_path\", file_key),\n",
    "                (\"file_name\", file_name),\n",
    "                (\"file_type\", file_ext)\n",
    "            ])\n",
    "            final_output.update(analysis)\n",
    "            \n",
    "            # Save locally\n",
    "            with open(local_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_output, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Upload to S3\n",
    "            json_key = os.path.join(\n",
    "                config['aws']['extract_txt_path'],\n",
    "                json_filename\n",
    "            ).replace('\\\\', '/')\n",
    "            \n",
    "            s3_client.put_object(\n",
    "                Bucket=config['aws']['txt_extract_bucket_name'],\n",
    "                Key=json_key,\n",
    "                Body=json.dumps(final_output, ensure_ascii=False, indent=2).encode('utf-8')\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully processed: {file_name}\")\n",
    "            print(f\"JSON saved: {local_json_path}\")\n",
    "            print(f\"Uploaded to: s3://{config['aws']['txt_extract_bucket_name']}/{json_key}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}:\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            if os.path.exists(tmp_file_path):\n",
    "                try:\n",
    "                    os.remove(tmp_file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error cleaning up {tmp_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0e13fb5-d481-44d6-aaf3-787e5d9cf2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 files to process\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/AWS Practitioner Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/AWS Practitioner Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: AWS Practitioner Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\AWS Practitioner Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/AWS Practitioner Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/AWS Solution Architect Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/AWS Solution Architect Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: AWS Solution Architect Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\AWS Solution Architect Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/AWS Solution Architect Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/CC Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/CC Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CC Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CC Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CC Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/CCNA Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/CCNA Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CCNA Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CCNA Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CCNA Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/CCSP Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/CCSP Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CCSP Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CCSP Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CCSP Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/CISSP Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/CISSP Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CISSP Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CISSP Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CISSP Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/DPO Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/DPO Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: DPO Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\DPO Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/DPO Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/FinOps Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/FinOps Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: FinOps Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\FinOps Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/FinOps Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/JPG/Fortinet NSE Sylabus.jpg\n",
      "Downloading ds/rag01/sources/JPG/Fortinet NSE Sylabus.jpg\n",
      "Analyzing JPG with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: Fortinet NSE Sylabus.jpg\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\Fortinet NSE Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/Fortinet NSE Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/AWS Practitioner Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/AWS Practitioner Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: AWS Practitioner Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\AWS Practitioner Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/AWS Practitioner Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/AWS Solution Architect Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/AWS Solution Architect Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: AWS Solution Architect Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\AWS Solution Architect Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/AWS Solution Architect Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Advanced Project Management Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Advanced Project Management Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: Advanced Project Management Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\Advanced Project Management Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/Advanced Project Management Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/BI Fin Ops Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/BI Fin Ops Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: BI Fin Ops Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\BI Fin Ops Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/BI Fin Ops Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CC Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CC Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CC Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CC Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CC Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CCNA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CCNA Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CCNA Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CCNA Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CCNA Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CCSP Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CCSP Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CCSP Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CCSP Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CCSP Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CDAIO-CDO Intro.pdf\n",
      "Downloading ds/rag01/sources/PDF/CDAIO-CDO Intro.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CDAIO-CDO Intro.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CDAIO-CDO Intro.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CDAIO-CDO Intro.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CDAIO-CDO Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CDAIO-CDO Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CDAIO-CDO Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CDAIO-CDO Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CDAIO-CDO Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CISCO CCNA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CISCO CCNA Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CISCO CCNA Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CISCO CCNA Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CISCO CCNA Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CISO Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CISO Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CISO Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CISO Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CISO Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CISSP Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CISSP Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CISSP Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CISSP Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CISSP Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/CND Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/CND Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: CND Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\CND Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/CND Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Check Point CCSA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Check Point CCSA Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: Check Point CCSA Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\Check Point CCSA Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/Check Point CCSA Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DMP Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DMP Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: DMP Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\DMP Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/DMP Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DPO Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DPO Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: DPO Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\DPO Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/DPO Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DS & AI for Managers Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DS & AI for Managers Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: DS & AI for Managers Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\DS & AI for Managers Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/DS & AI for Managers Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Data Science Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Data Science Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: Data Science Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\Data Science Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/Data Science Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/DevSecOps Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/DevSecOps Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: DevSecOps Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\DevSecOps Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/DevSecOps Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/FinOps Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/FinOps Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: FinOps Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\FinOps Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/FinOps Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Fortinet NSE Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Fortinet NSE Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: Fortinet NSE Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\Fortinet NSE Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/Fortinet NSE Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/Product Management Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/Product Management Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: Product Management Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\Product Management Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/Product Management Sylabus.json\n",
      "\n",
      "Processing: ds/rag01/sources/PDF/QA Sylabus.pdf\n",
      "Downloading ds/rag01/sources/PDF/QA Sylabus.pdf\n",
      "Analyzing PDF with Claude...\n",
      "Error analyzing with Claude: name 'base64' is not defined\n",
      "Full error context:  name 'base64' is not defined\n",
      "Successfully processed: QA Sylabus.pdf\n",
      "JSON saved: C:\\github_repos\\BIU_LLM_Project\\output\\json\\QA Sylabus.json\n",
      "Uploaded to: s3://ct-external-sources/ds/rag01/extract/QA Sylabus.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    try:\n",
    "        config = load_config()\n",
    "        process_files(config)\n",
    "    except Exception as e:\n",
    "        print(f\"Main process error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edc26b-c9b3-4af7-8045-52c0b767d47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef main():\\n    config = load_config()\\n    process_files(config)\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ecf36a-e3ec-484b-bcae-af24e20041ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_Projects",
   "language": "python",
   "name": "llm_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
