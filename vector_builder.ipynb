{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f06534-11a2-416e-b8f3-66b52a7238af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json5\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Document\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "from config.config_helper import pinecone_api_key, openai_api_key\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "MAX_TOKENS = 4096\n",
    "# Initialize tokenizer for the embedding model\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f834c3c-32a2-432d-b4f8-039dcf0d1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file):\n",
    "    # Load configuration from the YAML file\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f9b440-3ecf-4506-9539-a9d41df1d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pincone(config):\n",
    "    \"\"\"Initialize Pincone API from configuration.\"\"\"\n",
    "    \n",
    "    api_key = config['pinecone']['pinecone_api_key']\n",
    "    pc = Pinecone(api_key)\n",
    "    \n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b00f52-ce77-4413-8ac5-8b3e6a2a6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "def init_openai_embedding(config):\n",
    "    \"\"\"Initialize OpenAI API for embeddings.\"\"\"\n",
    "    \n",
    "    # Get the OpenAI API key from the configuration\n",
    "    api_key = config['openai']['chat_gpt_key']\n",
    "    \n",
    "    # Initialize OpenAIEmbedding with the correct parameters\n",
    "    client = OpenAIEmbedding(\n",
    "        model=\"text-embedding-ada-002\",  # Specify the embedding model\n",
    "        api_key=api_key  # Pass the API key\n",
    "    )\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bedfdadc-3c56-47db-a693-22cbf277e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks\n",
    "def chunk_text(text, max_tokens=MAX_TOKENS, overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_tokens,\n",
    "        chunk_overlap=overlap,\n",
    "        \n",
    "        # separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "        separators=[\"\\n\\n\", \"\\n\"]\n",
    "    )\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "\n",
    "# Function to clean metadata\n",
    "def clean_metadata(metadata):\n",
    "    cleaned_metadata = {}\n",
    "    for key, value in metadata.items():\n",
    "        if isinstance(value, (str, int, float, bool)):\n",
    "            cleaned_metadata[key] = value\n",
    "        elif isinstance(value, list) and all(isinstance(item, str) for item in value):\n",
    "            cleaned_metadata[key] = value\n",
    "    return cleaned_metadata\n",
    "\n",
    "\n",
    "# Create and configure Pinecone index\n",
    "def initialize_index(pc, index_name=\"biullmindex\"):\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        pc.delete_index(name=index_name)\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    return pc.Index(index_name)\n",
    "\n",
    "\n",
    "# Function to add documents to Pinecone\n",
    "def add_documents_to_pinecone(pc, documents, pinecone_index):\n",
    "    for i, doc in enumerate(documents):\n",
    "        metadata = clean_metadata(doc.metadata)\n",
    "        if len(tokenizer.encode(doc.text)) > MAX_TOKENS:\n",
    "            chunks = chunk_text(doc.text)\n",
    "            for j, chunk in enumerate(chunks):\n",
    "                chunk_id = f\"doc-{i}-chunk-{j}\"\n",
    "                embedding = client.get_text_embedding(chunk)\n",
    "                pinecone_index.upsert(\n",
    "                    vectors=[(chunk_id, embedding, {**metadata, \"chunk_id\": chunk_id})]\n",
    "                )\n",
    "        else:\n",
    "            embedding = client.get_text_embedding(doc.text)\n",
    "            pinecone_index.upsert(\n",
    "                vectors=[(f\"doc-{i}\", embedding, metadata)]\n",
    "            )\n",
    "\n",
    "\n",
    "# Main function to populate the database\n",
    "def populate_vector_db(config, data_path, index_name=\"biullmindex\"):\n",
    "\n",
    "    # Initialize Pinecone client\n",
    "    pc = init_pincone (config)\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    client = init_openai_embedding(config)\n",
    "    \n",
    "    pinecone_index = initialize_index(index_name)\n",
    "    \n",
    "    documents = []\n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(data_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                text_content = data.get('full_text', '')\n",
    "                \n",
    "                metadata_keys = ['course_name', 'summary']\n",
    "                metadata = {key: value for key, value in data.items() if key in metadata_keys}\n",
    "           \n",
    "                if text_content:\n",
    "                    documents.append(Document(text=text_content, metadata=metadata))\n",
    "                    \n",
    "    add_documents_to_pinecone(pc, documents, pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9ce718-adf6-4249-bde4-18c60390baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\github_repos\\BIU_LLM_Project\n",
      "Jsons docs path: C:\\github_repos\\BIU_LLM_Project\\data\\documents\\eng\n",
      "Main process error: 'str' object has no attribute 'list_indexes'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'list_indexes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     json_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cwd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJsons docs path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, json_path)\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mpopulate_vector_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbiullmindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m      \n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain process error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m, in \u001b[0;36mpopulate_vector_db\u001b[1;34m(config, data_path, index_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Initialize OpenAI client\u001b[39;00m\n\u001b[0;32m     63\u001b[0m client \u001b[38;5;241m=\u001b[39m init_openai_embedding(config)\n\u001b[1;32m---> 65\u001b[0m pinecone_index \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m documents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path):\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36minitialize_index\u001b[1;34m(pc, index_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_index\u001b[39m(pc, index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiullmindex\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m()\u001b[38;5;241m.\u001b[39mnames():\n\u001b[0;32m     27\u001b[0m         pc\u001b[38;5;241m.\u001b[39mdelete_index(name\u001b[38;5;241m=\u001b[39mindex_name)\n\u001b[0;32m     28\u001b[0m     pc\u001b[38;5;241m.\u001b[39mcreate_index(\n\u001b[0;32m     29\u001b[0m         name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[0;32m     30\u001b[0m         dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1536\u001b[39m,\n\u001b[0;32m     31\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m         spec\u001b[38;5;241m=\u001b[39mServerlessSpec(cloud\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maws\u001b[39m\u001b[38;5;124m\"\u001b[39m, region\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-east-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'list_indexes'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Build Embedding Vector DB\n",
    "    \"\"\"    \n",
    "    \n",
    "    cwd =os.getcwd()\n",
    "    print(\"Current working directory:\", cwd)\n",
    "    \n",
    "    try:\n",
    "        # Extract parameters from the configuration\n",
    "        config_file = 'config/config.yaml'\n",
    "        config = load_config(config_file)\n",
    "                \n",
    "        # Json Documents on aws s3 - Production\n",
    "        region_name = config['aws']['region_name']\n",
    "        source_bucket_name = config['aws']['txt_extract_bucket_name']\n",
    "        source_path = config['aws']['txt_extract_path']    \n",
    "        log_file = 'get_json_sources'\n",
    "        \n",
    "        # Json Documents on aws s3 - Develop\n",
    "        json_path = os.path.join(cwd, 'data','documents','eng')\n",
    "        print(\"Jsons docs path:\", json_path)\n",
    "\n",
    "        populate_vector_db(config, json_path, index_name=\"biullmindex\")      \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Main process error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIU LLM Project",
   "language": "python",
   "name": "biu-llm-project-ewdi__u5-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
