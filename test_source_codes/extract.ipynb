{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7137f52c-8862-44bb-bc10-799764436e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import boto3\n",
    "import io\n",
    "import base64  # Added base64 import\n",
    "from PIL import Image\n",
    "from anthropic import Anthropic\n",
    "from collections import OrderedDict\n",
    "from botocore.exceptions import NoCredentialsError, ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7012495-6a16-4119-8971-f6125e837eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\github_repos\\BIU_LLM_Project\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae29739d-a8a4-45c1-9e4d-e2bda6fc83ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main process error: name 'yaml' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'yaml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 231\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 231\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 224\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main entry point\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     process_files(config)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load configuration from YAML file\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig/config.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43myaml\u001b[49m\u001b[38;5;241m.\u001b[39msafe_load(file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yaml' is not defined"
     ]
    }
   ],
   "source": [
    "def load_config():\n",
    "    \"\"\"Load configuration from YAML file\"\"\"\n",
    "    with open('config/config.yaml', 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_aws_client(config):\n",
    "    \"\"\"Initialize AWS S3 client\"\"\"\n",
    "    return boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=config['aws']['aws_access_key_id'],\n",
    "        aws_secret_access_key=config['aws']['aws_secret_access_key'],\n",
    "        region_name=config['aws']['region_name']\n",
    "    )\n",
    "\n",
    "def init_claude(config):\n",
    "    \"\"\"Initialize Claude client\"\"\"\n",
    "    return Anthropic(\n",
    "        api_key=config['anthropic']['claud_key']\n",
    "    )\n",
    "\n",
    "def get_s3_public_url(bucket_name, file_key, region):\n",
    "    \"\"\"Generate S3 public URL\"\"\"\n",
    "    return f\"https://{bucket_name}.s3.{region}.amazonaws.com/{file_key}\"\n",
    "\n",
    "def ensure_tmp_dir():\n",
    "    \"\"\"Create and clean temporary directory\"\"\"\n",
    "    tmp_dir = os.path.join(os.getcwd(), 'tmp')\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "    else:\n",
    "        for filename in os.listdir(tmp_dir):\n",
    "            file_path = os.path.join(tmp_dir, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Error deleting {file_path}: {e}')\n",
    "    return tmp_dir\n",
    "\n",
    "def analyze_with_claude(client, file_path, file_type):\n",
    "    \"\"\"Send file to Claude for analysis\"\"\"\n",
    "    prompt = \"\"\"\n",
    "                Analyze this document and extract the following information in JSON format. The document contains course syllabus information,\n",
    "                likely in both Hebrew and English. Required JSON structure: { \"course_name\": \"Course name in original language\",\n",
    "                \"program_manager\": \"Look for 'מנהל התוכנית' or program manager\",\n",
    "                \"instructors\": [ { \"name\": \"Instructor name\", \"role\": \"Role (e.g., יועץ מקצועי, מרצה, מרצה בכיר, מדריך)\", \"title\": \"Professional title if available\", \"description\": \"Additional description or background\" } ],\n",
    "                \"summary\": \"A comprehensive summary of the course content\", \"embedded_images\": [\"List of image references\"],\n",
    "                \"full_text\": \"The complete text from the document\" } Keep all text in its original language (Hebrew and English). Give the full text.\n",
    "                IMPORTANT NOTES:\n",
    "                1. If a field is not found, use null or empty array [].\n",
    "                2. I gave you the accurate json format. DO NOT add more entries to the json file.\n",
    "                3. You need extract the the text from the entire document.\n",
    "             \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Read and encode file\n",
    "        with open(file_path, 'rb') as file:\n",
    "            file_content = file.read()\n",
    "            file_b64 = base64.b64encode(file_content).decode('utf-8')\n",
    "\n",
    "        # Set media type\n",
    "        media_type = \"application/pdf\" if file_type == \"pdf\" else f\"image/{file_type}\"\n",
    "\n",
    "        # Create message\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-3.5-sonnet\",\n",
    "            max_tokens=100000,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": media_type,\n",
    "                                \"data\": file_b64\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(\"Raw Claude Response:\", message.content[0].text[:500] + \"...\")\n",
    "        response_text = message.content[0].text.strip()\n",
    "        \n",
    "        try:\n",
    "            start = response_text.find('{')\n",
    "            end = response_text.rfind('}') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                json_str = response_text[start:end]\n",
    "                print(\"Extracted JSON string:\", json_str[:500] + \"...\")\n",
    "                claude_response = json.loads(json_str)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON found in response\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Parse Error: {str(e)}\")\n",
    "            print(f\"Response text: {response_text}\")\n",
    "            raise\n",
    "        \n",
    "        return OrderedDict([\n",
    "            (\"course_name\", claude_response.get(\"course_name\", \"\")),\n",
    "            (\"program_manager\", claude_response.get(\"program_manager\", \"\")),\n",
    "            (\"instructors\", claude_response.get(\"instructors\", [])),\n",
    "            (\"summary\", claude_response.get(\"summary\", \"\")),\n",
    "            (\"embedded_images\", claude_response.get(\"embedded_images\", [])),\n",
    "            (\"full_text\", claude_response.get(\"full_text\", \"\"))\n",
    "        ])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing with Claude: {str(e)}\")\n",
    "        print(f\"Full error context: \", e)\n",
    "        return OrderedDict([\n",
    "            (\"course_name\", \"\"),\n",
    "            (\"program_manager\", \"\"),\n",
    "            (\"instructors\", []),\n",
    "            (\"summary\", f\"Error analyzing content: {str(e)}\"),\n",
    "            (\"embedded_images\", []),\n",
    "            (\"full_text\", \"\")\n",
    "        ])\n",
    "\n",
    "def process_files(config):\n",
    "    \"\"\"Main processing function\"\"\"\n",
    "    s3_client = init_aws_client(config)\n",
    "    claude_client = init_claude(config)\n",
    "    \n",
    "    tmp_dir = ensure_tmp_dir()\n",
    "    json_output_dir = os.path.join(os.getcwd(), 'output', 'json')\n",
    "    os.makedirs(json_output_dir, exist_ok=True)\n",
    "    \n",
    "    def list_all_files(bucket, prefix):\n",
    "        \"\"\"Recursively list all supported files\"\"\"\n",
    "        files = []\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "            if 'Contents' in page:\n",
    "                for obj in page['Contents']:\n",
    "                    file_ext = os.path.splitext(obj['Key'])[1].lower()\n",
    "                    if file_ext in ['.pdf', '.jpg', '.jpeg', '.png']:\n",
    "                        files.append(obj)\n",
    "        \n",
    "        return files\n",
    "\n",
    "    files = list_all_files(\n",
    "        config['aws']['upload_bucket_name'],\n",
    "        config['aws']['upload_path']\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(files)} files to process\")\n",
    "    \n",
    "    for file_obj in files:\n",
    "        file_key = file_obj['Key']\n",
    "        file_name = os.path.basename(file_key)\n",
    "        file_ext = os.path.splitext(file_name)[1].lower()[1:]  # Remove the dot\n",
    "        \n",
    "        print(f\"\\nProcessing: {file_key}\")\n",
    "        \n",
    "        tmp_file_path = os.path.join(tmp_dir, file_name)\n",
    "        json_filename = f\"{os.path.splitext(file_name)[0]}.json\"\n",
    "        local_json_path = os.path.join(json_output_dir, json_filename)\n",
    "        \n",
    "        try:\n",
    "            print(f\"Downloading {file_key}\")\n",
    "            s3_client.download_file(\n",
    "                config['aws']['upload_bucket_name'],\n",
    "                file_key,\n",
    "                tmp_file_path\n",
    "            )\n",
    "\n",
    "            print(f\"Analyzing {file_ext.upper()} with Claude...\")\n",
    "            analysis = analyze_with_claude(claude_client, tmp_file_path, file_ext)\n",
    "            \n",
    "            final_output = OrderedDict([\n",
    "                (\"file_url\", get_s3_public_url(\n",
    "                    config['aws']['upload_bucket_name'],\n",
    "                    file_key,\n",
    "                    config['aws']['region_name']\n",
    "                )),\n",
    "                (\"file_path\", file_key),\n",
    "                (\"file_name\", file_name),\n",
    "                (\"file_type\", file_ext)\n",
    "            ])\n",
    "            final_output.update(analysis)\n",
    "            \n",
    "            # Save locally\n",
    "            with open(local_json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_output, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Upload to S3\n",
    "            json_key = os.path.join(\n",
    "                config['aws']['extract_txt_path'],\n",
    "                json_filename\n",
    "            ).replace('\\\\', '/')\n",
    "            \n",
    "            s3_client.put_object(\n",
    "                Bucket=config['aws']['txt_extract_bucket_name'],\n",
    "                Key=json_key,\n",
    "                Body=json.dumps(final_output, ensure_ascii=False, indent=2).encode('utf-8')\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully processed: {file_name}\")\n",
    "            print(f\"JSON saved: {local_json_path}\")\n",
    "            print(f\"Uploaded to: s3://{config['aws']['txt_extract_bucket_name']}/{json_key}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}:\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            if os.path.exists(tmp_file_path):\n",
    "                try:\n",
    "                    os.remove(tmp_file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error cleaning up {tmp_file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    try:\n",
    "        config = load_config()\n",
    "        process_files(config)\n",
    "    except Exception as e:\n",
    "        print(f\"Main process error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18c08e-ff42-4a72-8608-93f7667d9c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
